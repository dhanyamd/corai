
from maya.chains import get_chain, get_code_response
from maya.state import CoraiAgentState
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import AIMessage, HumanMessage, RemoveMessage


async def input_node(state: CoraiAgentState, config: RunnableConfig ): 
    """
    Contains a prompt and code from the user as input, then generates the detailed
    summary for the prompt and returns the detailed summary and code back.

    Args: 
        messages: str | list[str] | list[dict[str, any]]
    Yields: 
        summary: str 
        code : str | list[str]
    """
    initial_prompt = state.get("messages", "")
    print(f"Input Node received: {initial_prompt}")
    chain = get_chain(initial_prompt)
    response = await chain.ainvoke({"messages": initial_prompt}, config)
    return {"summary": AIMessage(content=response) }
    
async def response_node(state: CoraiAgentState, config: RunnableConfig):
    """
    Takes the summary generated and code back by the input_node back and generates code 
    for the requested query. The response would be the code block generated by the LLM.

    Args: 
      summary (str) : The summary generated by the input_node
    Returns: 
      code (str): The response or the code generated through the summary and the code provided. 
      It returns a code block containing all the changes as guided by the summary prompt.
    """
    summary = state.get("summary")
    print(f"summary: ", {summary})
    chain =  get_code_response(summary=summary)
    code_gen = await chain.ainvoke({"summary": summary, "messsages": state["messages"]}, config)
    messages = state["messages"] + HumanMessage(content=summary)
    return {"code": AIMessage(content=code_gen)} 


